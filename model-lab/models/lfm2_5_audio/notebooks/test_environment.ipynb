{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Environment Validation Test\n",
    "\n",
    "This notebook validates that your UV environment is properly configured for model testing.\n",
    "\n",
    "## Expected Results:\n",
    "- ‚úÖ All imports should work without errors\n",
    "- ‚úÖ Torch should detect MPS (Apple Silicon) device\n",
    "- ‚úÖ All libraries should show correct versions\n",
    "- ‚úÖ Audio files should be accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Python Environment Check\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print('üêç Python Environment Check')\n",
    "print('=' * 50)\n",
    "print(f'Python executable: {sys.executable}')\n",
    "print(f'Python version: {sys.version}')\n",
    "print(f'Python prefix: {sys.prefix}')\n",
    "print()\n",
    "\n",
    "# Check if we're in the right environment\n",
    "expected_path = '/Users/pranay/Projects/speech_experiments/model-lab/.venv'\n",
    "if sys.prefix.startswith(expected_path):\n",
    "    print('‚úÖ CORRECT: Using model-lab UV environment')\n",
    "else:\n",
    "    print(f'‚ùå WRONG: Not using model-lab environment')\n",
    "    print(f'Expected: {expected_path}')\n",
    "    print(f'Got: {sys.prefix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Critical Library Imports\n",
    "print('üìö Critical Library Imports')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test torch\n",
    "try:\n",
    "    import torch\n",
    "    print(f'‚úÖ torch: {torch.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå torch: {e}')\n",
    "\n",
    "# Test torchaudio\n",
    "try:\n",
    "    import torchaudio\n",
    "    print(f'‚úÖ torchaudio: {torchaudio.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå torchaudio: {e}')\n",
    "\n",
    "# Test liquid-audio\n",
    "try:\n",
    "    from liquid_audio import LFM2AudioModel, LFM2AudioProcessor, ChatState\n",
    "    print('‚úÖ liquid-audio: imports work')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå liquid-audio: {e}')\n",
    "\n",
    "# Test numpy\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f'‚úÖ numpy: {np.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå numpy: {e}')\n",
    "\n",
    "# Test librosa\n",
    "try:\n",
    "    import librosa\n",
    "    print(f'‚úÖ librosa: {librosa.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå librosa: {e}')\n",
    "\n",
    "# Test pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(f'‚úÖ pandas: {pd.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå pandas: {e}')\n",
    "\n",
    "# Test matplotlib\n",
    "try:\n",
    "    import matplotlib\n",
    "    print(f'‚úÖ matplotlib: {matplotlib.__version__}')\n",
    "except ImportError as e:\n",
    "    print(f'‚ùå matplotlib: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Device and Hardware Check\n",
    "print('üñ•Ô∏è  Device and Hardware Check')\n",
    "print('=' * 50)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check CUDA\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f'CUDA available: {cuda_available}')\n",
    "if cuda_available:\n",
    "    print(f'CUDA device: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "# Check MPS (Apple Silicon)\n",
    "mps_available = torch.backends.mps.is_available()\n",
    "print(f'MPS available: {mps_available}')\n",
    "if mps_available:\n",
    "    print('‚úÖ MPS (Apple Silicon) acceleration available')\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print('‚ö†Ô∏è  MPS not available, using CPU')\n",
    "    device = 'cpu'\n",
    "\n",
    "# Check CPU\n",
    "import platform\n",
    "print(f'CPU: {platform.processor()}')\n",
    "print(f'Machine: {platform.machine()}')\n",
    "print(f'Platform: {platform.platform()}')\n",
    "\n",
    "print(f'\\nüéØ Using device: {device.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test File System Access\n",
    "from pathlib import Path\n",
    "\n",
    "print('üìÅ File System Access Check')\n",
    "print('=' * 50)\n",
    "\n",
    "# Check current directory\n",
    "current_dir = Path.cwd()\n",
    "print(f'Current directory: {current_dir}')\n",
    "\n",
    "# Check data directories\n",
    "audio_dir = Path('data/audio')\n",
    "text_dir = Path('data/text')\n",
    "\n",
    "if audio_dir.exists():\n",
    "    audio_files = list(audio_dir.glob('*.wav'))\n",
    "    print(f'‚úÖ Audio directory exists: {len(audio_files)} WAV files')\n",
    "    for audio_file in audio_files[:5]:\n",
    "        print(f'   - {audio_file.name}')\n",
    "else:\n",
    "    print('‚ùå Audio directory not found')\n",
    "\n",
    "if text_dir.exists():\n",
    "    text_files = list(text_dir.glob('*.txt'))\n",
    "    print(f'‚úÖ Text directory exists: {len(text_files)} TXT files')\n",
    "    for text_file in text_files[:5]:\n",
    "        print(f'   - {text_file.name}')\n",
    "else:\n",
    "    print('‚ùå Text directory not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test Audio Loading\n",
    "import torchaudio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print('üéµ Audio Loading Test')\n",
    "print('=' * 50)\n",
    "\n",
    "# Test loading canonical audio\n",
    "audio_path = Path('data/audio/clean_speech_10s.wav')\n",
    "\n",
    "if audio_path.exists():\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(str(audio_path))\n",
    "        print(f'‚úÖ Successfully loaded: {audio_path.name}')\n",
    "        print(f'   Shape: {waveform.shape}')\n",
    "        print(f'   Sample rate: {sr} Hz')\n",
    "        print(f'   Duration: {waveform.shape[1]/sr:.1f} seconds')\n",
    "        print(f'   Data type: {waveform.dtype}')\n",
    "        print(f'   Min/Max: {waveform.min():.3f} / {waveform.max():.3f}')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error loading audio: {e}')\n",
    "else:\n",
    "    print(f'‚ùå Audio file not found: {audio_path}')\n",
    "\n",
    "# Test conversation audio\n",
    "conv_path = Path('data/audio/conversation_2ppl_10s.wav')\n",
    "if conv_path.exists():\n",
    "    try:\n",
    "        conv_waveform, conv_sr = torchaudio.load(str(conv_path))\n",
    "        print(f'\\n‚úÖ Successfully loaded: {conv_path.name}')\n",
    "        print(f'   Shape: {conv_waveform.shape}')\n",
    "        print(f'   Duration: {conv_waveform.shape[1]/conv_sr:.1f} seconds')\n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ùå Error loading conversation: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test LFM Model Loading (Basic)\n",
    "from liquid_audio import LFM2AudioProcessor\n",
    "from liquid_audio.processor import PreprocessorConfig\n",
    "\n",
    "print('üîß LFM Model Component Test')\n",
    "print('=' * 50)\n",
    "\n",
    "HF_REPO = 'LiquidAI/LFM2.5-Audio-1.5B'\n",
    "\n",
    "try:\n",
    "    # Create audio processor config\n",
    "    audio_config = PreprocessorConfig(\n",
    "        sample_rate=24000,\n",
    "        features=128,\n",
    "        normalize='per_feature',\n",
    "        window_size=0.02,\n",
    "        window_stride=0.01, \n",
    "        window='hann',\n",
    "        n_fft=512,\n",
    "        log=True,\n",
    "        frame_splicing=1,\n",
    "        dither=1e-5,\n",
    "        pad_to=16,\n",
    "        pad_value=0\n",
    "    )\n",
    "    print('‚úÖ PreprocessorConfig created')\n",
    "    \n",
    "    # Create processor\n",
    "    processor = LFM2AudioProcessor(\n",
    "        text_tokenizer_path=HF_REPO,\n",
    "        audio_processor_config=audio_config\n",
    "    )\n",
    "    print('‚úÖ LFM2AudioProcessor created')\n",
    "    print(f'   Vocabulary size: {len(processor.text_tokenizer):,} tokens')\n",
    "    \n",
    "    print(f'\\nüéâ LFM components working correctly!')\n",
    "    print(f'üìä Repository: {HF_REPO}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ùå LFM setup failed: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test Simple Audio Processing\n",
    "import torchaudio\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print('üéõÔ∏è  Audio Processing Test')\n",
    "print('=' * 50)\n",
    "\n",
    "audio_path = Path('data/audio/clean_speech_10s.wav')\n",
    "\n",
    "if audio_path.exists():\n",
    "    try:\n",
    "        # Load audio\n",
    "        waveform, sr = torchaudio.load(str(audio_path))\n",
    "        print(f'Original: {waveform.shape}, {sr} Hz')\n",
    "        \n",
    "        # Test resampling\n",
    "        if sr != 24000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 24000)\n",
    "            waveform_24k = resampler(waveform)\n",
    "            print(f'‚úÖ Resampled to: {waveform_24k.shape}, 24000 Hz')\n",
    "        \n",
    "        # Test mono conversion\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform_mono = waveform.mean(dim=0, keepdim=True)\n",
    "            print(f'‚úÖ Converted to mono: {waveform_mono.shape}')\n",
    "        \n",
    "        # Test normalization\n",
    "        waveform_norm = waveform / waveform.abs().max()\n",
    "        print(f'‚úÖ Normalized: range [{waveform_norm.min():.3f}, {waveform_norm.max():.3f}]')\n",
    "        \n",
    "        # Test spectrogram\n",
    "        spectrogram_transform = torchaudio.transforms.Spectrogram()\n",
    "        spectrogram = spectrogram_transform(waveform)\n",
    "        print(f'‚úÖ Spectrogram: {spectrogram.shape}')\n",
    "        \n",
    "        # Test Mel spectrogram\n",
    "        mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_mels=128)\n",
    "        mel_spectrogram = mel_transform(waveform)\n",
    "        print(f'‚úÖ Mel spectrogram: {mel_spectrogram.shape}')\n",
    "        \n",
    "        print('\\nüéâ Audio processing pipeline working!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Audio processing failed: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f'‚ùå Test audio not found: {audio_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Summary and Recommendations\n",
    "print('üìã ENVIRONMENT VALIDATION SUMMARY')\n",
    "print('=' * 50)\n",
    "print()\n",
    "print('‚úÖ Checks completed:')\n",
    "print('   ‚Ä¢ Python environment configuration')\n",
    "print('   ‚Ä¢ Library import validation')\n",
    "print('   ‚Ä¢ Hardware acceleration detection')\n",
    "print('   ‚Ä¢ File system access')\n",
    "print('   ‚Ä¢ Audio loading capability')\n",
    "print('   ‚Ä¢ LFM component initialization')\n",
    "print('   ‚Ä¢ Audio processing pipeline')\n",
    "print()\n",
    "print('üéØ Next Steps:')\n",
    "print('   1. Run full LFM model testing notebook')\n",
    "print('   2. Test transcription capabilities')\n",
    "print('   3. Run performance benchmarks')\n",
    "print('   4. Compare with other models')\n",
    "print()\n",
    "print('üöÄ Your environment is ready for systematic model testing!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (model-lab)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}