{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper ASR Evaluation\n",
    "\n",
    "**Purpose**: Comprehensive ASR testing using Whisper baseline\n",
    "\n",
    "**Tests**: Full-length audio transcription with metrics\n",
    "\n",
    "---\n",
    "\n",
    "This notebook evaluates Whisper's ASR performance on your test recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add harness to path\n",
    "harness_path = Path.cwd().parent.parent / \"harness\"\n",
    "sys.path.insert(0, str(harness_path))\n",
    "\n",
    "import torch\n",
    "import whisper\n",
    "import yaml\n",
    "\n",
    "from harness import AudioLoader, ModelRegistry, PerformanceTimer\n",
    "from harness.metrics_asr import ASRMetrics\n",
    "\n",
    "print(\"=== Whisper ASR Evaluation ===\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD MODEL ===\n",
    "\n",
    "config_path = Path.cwd().parent / \"config.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model_wrapper = ModelRegistry.load_model(\"whisper\", config, device)\n",
    "model = model_wrapper[\"model\"]\n",
    "\n",
    "print(f\"âœ“ Whisper model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD TEST DATA ===\n",
    "\n",
    "# Test audio\n",
    "test_audio_path = (\n",
    "    Path.cwd().parent.parent.parent / \"data\" / \"audio\" / \"PRIMARY\" / \"llm_recording_pranay.m4a\"\n",
    ")\n",
    "ground_truth_path = Path.cwd().parent.parent.parent / \"data\" / \"text\" / \"PRIMARY\" / \"llm.txt\"\n",
    "\n",
    "print(f\"Loading audio: {test_audio_path.name}\")\n",
    "\n",
    "loader = AudioLoader(target_sample_rate=16000)\n",
    "audio, sr, audio_metadata = loader.load_audio(test_audio_path, \"whisper\")\n",
    "\n",
    "# Load ground truth\n",
    "from harness import GroundTruthLoader\n",
    "\n",
    "ground_truth = GroundTruthLoader.load_text(ground_truth_path)\n",
    "\n",
    "print(f\"âœ“ Audio loaded: {audio_metadata['duration_seconds']:.1f}s\")\n",
    "print(f\"âœ“ Ground truth: {len(ground_truth)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN TRANSCRIPTION ===\n",
    "\n",
    "timer = PerformanceTimer()\n",
    "\n",
    "print(\"Transcribing audio...\")\n",
    "with timer.time_operation(\"whisper_full_transcribe\"):\n",
    "    result = model.transcribe(audio, language=\"en\")\n",
    "\n",
    "transcription = result[\"text\"].strip()\n",
    "latency_ms = timer.elapsed_time_ms\n",
    "\n",
    "print(f\"\\n=== TRANSCRIPTION RESULTS ===\")\n",
    "print(f\"Latency: {latency_ms:.1f}ms\")\n",
    "print(f\"RTF: {latency_ms / 1000 / audio_metadata['duration_seconds']:.3f}x\")\n",
    "print(f\"Transcription length: {len(transcription)} chars\")\n",
    "print(f\"\\nTranscription:\")\n",
    "print(transcription[:200] + \"...\" if len(transcription) > 200 else transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CALCULATE METRICS ===\n",
    "\n",
    "asr_result = ASRMetrics.evaluate(\n",
    "    transcription=transcription,\n",
    "    ground_truth=ground_truth,\n",
    "    audio_duration_s=audio_metadata[\"duration_seconds\"],\n",
    "    latency_s=latency_ms / 1000,\n",
    "    metadata={\n",
    "        \"model\": \"whisper-large-v3\",\n",
    "        \"audio_file\": str(test_audio_path.name),\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"\\n=== ASR METRICS ===\")\n",
    "print(f\"WER: {asr_result.wer:.3f} ({asr_result.wer * 100:.1f}%)\")\n",
    "print(f\"CER: {asr_result.cer:.3f} ({asr_result.cer * 100:.1f}%)\")\n",
    "print(f\"Latency: {asr_result.latency_ms:.1f}ms\")\n",
    "print(f\"RTF: {asr_result.rtv:.3f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE RESULTS ===\n",
    "\n",
    "# Create results directory\n",
    "results_dir = Path.cwd().parent.parent.parent / \"runs\" / \"whisper\" / \"asr\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "result_file = results_dir / f\"{timestamp}.json\"\n",
    "\n",
    "results = {\n",
    "    \"model\": \"whisper-large-v3\",\n",
    "    \"test_type\": \"asr\",\n",
    "    \"timestamp\": timestamp,\n",
    "    \"audio_file\": str(test_audio_path.name),\n",
    "    \"audio_duration_s\": audio_metadata[\"duration_seconds\"],\n",
    "    \"ground_truth_length\": len(ground_truth),\n",
    "    \"transcription_length\": len(transcription),\n",
    "    \"wer\": asr_result.wer,\n",
    "    \"cer\": asr_result.cer,\n",
    "    \"latency_ms\": asr_result.latency_ms,\n",
    "    \"rtf\": asr_result.rtv,\n",
    "    \"transcription\": transcription,\n",
    "    \"ground_truth\": ground_truth,\n",
    "}\n",
    "\n",
    "with open(result_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Results saved to: {result_file}\")\n",
    "print(f\"\\nðŸŽ‰ Whisper ASR evaluation complete!\")\n",
    "print(f\"âœ… Ready for comparison in compare/00_scorecard.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (model-lab)",
   "language": "python",
   "name": "model-lab"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}