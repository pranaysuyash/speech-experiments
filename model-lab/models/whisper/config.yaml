# Whisper Model Configuration
# OpenAI's Whisper model for ASR baseline comparison

model_name: large-v3
model_type: whisper

# Audio processing
audio:
  sample_rate: 16000
  channels: 1
  format: wav

# Inference settings
inference:
  dtype: float16
  beam_size: 5
  language: en


official_sources:
  - kind: "repo"
    url: "https://github.com/openai/whisper"
    note: "Official repository"
  - kind: "paper"
    url: "https://arxiv.org/abs/2212.04356"
    note: "Whisper paper"

declared_capabilities:
  - task: "asr"
    role: "primary"
    notes: "Production-grade general purpose ASR."
    
  - task: "alignment"
    role: "primary"
    notes: "Implicit alignment via high-quality timestamp generation."

claims:
  claimed_strengths:
    - "robustness"
    - "multilingual"
  recommended_usage:
    - "Transcription"
    - "Subtitle generation"

# Constraints
constraints:
  max_audio_length: 30
  max_memory_mb: 2000
  target_latency: 500

# Language settings
language:
  auto_detect: true
  fallback_language: en
  supported: ["en", "es", "fr", "de", "it", "pt", "nl", "ja", "zh", "ko"]

# =============================================================================
# Extended ModelCard Fields (for Arsenal doc generation)
# =============================================================================

# Deployment scope
deployment:
  runtimes: ["local", "api"]  # where it can run
  offline_capable: true
  targets: ["desktop", "server"]  # where it realistically works
  notes: "Mobile only via server API; local mobile not feasible due to model size."

# Hardware requirements
hardware:
  accelerators_supported: ["cpu", "mps", "cuda"]
  min_vram_gb: 4
  ram_gb_recommended: 8
  disk_gb_model: 2.5
  notes:
    - "MPS works well on Apple Silicon"
    - "CPU is slow but functional"

# Packaging artifacts
artifacts:
  - type: pytorch
    precision: ["fp32", "fp16"]
  - type: gguf
    precision: ["q4", "q5", "q8", "fp16"]
    notes: "via whisper.cpp"

# Installation
install:
  method: pip
  deps_pain: low
  known_issues:
    - "Requires ffmpeg for some audio formats"

# Recommendation (decision guidance)
recommendation:
  best_app_types: ["batch_transcription", "desktop_productivity", "call_analytics"]
  poor_app_types: ["real_time_voice_assistant", "mobile_voice_notes"]
  interaction_style: batch

# Metadata
metadata:
  provider: OpenAI
  version: large-v3
  released: 2023
  description: |
    Whisper is a general-purpose speech recognition model.
    Trained on 680,000 hours of multilingual data.
    Production-grade baseline for ASR comparison.
  license: MIT
  paper_url: https://arxiv.org/abs/2212.04356
  repo_url: https://github.com/openai/whisper