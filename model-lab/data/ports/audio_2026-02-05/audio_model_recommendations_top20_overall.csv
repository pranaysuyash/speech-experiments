model_id,family,version,local_or_api,category,tasks_supported,languages,streaming_support,runtime,quantization,hardware_reqs,docs_url,implementation_priority,priority_score,rank_overall,rank_production_safe,recommendation_rationale,consent_risk,maintenance_risk,integration_complexity,community_signal
silero-vad,Silero VAD,latest,Local,VAD,Voice activity detection; segmentation; stream chunking,language-agnostic,yes,PyTorch / ONNX,varies,CPU,https://github.com/snakers4/silero-vad,P0,196,1,1.0,P0; VAD; realtime; production; measurable; PyTorch / ONNX; varies,low,low,low,high
webrtcvad,WebRTC VAD,various,Local,VAD,Voice activity detection (classical),language-agnostic,yes,C / Python bindings,,CPU,https://github.com/wiseman/py-webrtcvad,P0,196,1,1.0,P0; VAD; realtime; production; measurable; C / Python bindings; nan,low,low,low,high
whisper-tiny-faster-whisper-ctranslate2-float32,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),float32,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); float32,,low,medium,very high
whisper-base-whisper-cpp-gguf-q8-0,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q8_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q8_0,,low,medium,very high
whisper-base-faster-whisper-ctranslate2-float16,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),float16,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); float16,,low,medium,very high
whisper-base-faster-whisper-ctranslate2-float32,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),float32,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); float32,,low,medium,very high
whisper-tiny-faster-whisper-ctranslate2-int8-float16,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),int8_float16,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); int8_float16,,low,medium,very high
whisper-tiny-faster-whisper-ctranslate2-float16,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),float16,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); float16,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q8-0,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q8_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q8_0,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q6-k,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q6_k,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q6_k,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q5-0,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q5_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q5_0,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q4-0,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q4_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q4_0,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q4-k-m,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q4_k_m,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q4_k_m,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q3-k-l,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q3_k_l,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q3_k_l,,low,medium,very high
whisper-tiny-whisper-cpp-gguf-q2-k,Whisper,tiny,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q2_k,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q2_k,,low,medium,very high
whisper-base-whisper-cpp-gguf-q6-k,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q6_k,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q6_k,,low,medium,very high
whisper-small-faster-whisper-ctranslate2-float32,Whisper,small,Local,ASR,"ASR, transcription",multilingual,Chunked streaming possible; best for batch throughput,faster-whisper (CTranslate2),float32,CPU ok; GPU recommended for throughput; compute_type controls speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; faster-whisper (CTranslate2); float32,,low,medium,very high
whisper-base-whisper-cpp-gguf-q5-0,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q5_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q5_0,,low,medium,very high
whisper-base-whisper-cpp-gguf-q4-0,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q4_0,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q4_0,,low,medium,very high
whisper-base-whisper-cpp-gguf-q4-k-m,Whisper,base,Local,ASR,"ASR, transcription",multilingual,Streaming via chunking; whisper.cpp supports realtime examples,whisper.cpp,gguf:q4_k_m,CPU; Apple Silicon Metal acceleration available; GGUF/GGML quant improves speed and memory,https://github.com/openai/whisper,P0,183,3,3.0,P0; ASR; near-realtime; production; measurable; whisper.cpp; gguf:q4_k_m,,low,medium,very high
