record_type,domain,model,metric,value_raw,value_num,unit,dataset_or_condition,hardware,source_context
benchmark,ASR,Whisper Tiny,WER,~9%,,,LibriSpeech Clean,Not stated,"Tiny … LibriSpeech Clean WER ~9%"
benchmark,ASR,Whisper Tiny,WER,~13%,,,LibriSpeech Other,Not stated,"Tiny … LibriSpeech Other WER ~13%"
benchmark,ASR,Whisper Base,WER,~6%,,,LibriSpeech Clean,Not stated,"Base … LibriSpeech Clean WER ~6%"
benchmark,ASR,Whisper Base,WER,~9%,,,LibriSpeech Other,Not stated,"Base … LibriSpeech Other WER ~9%"
benchmark,ASR,Whisper Small,WER,~4%,,,LibriSpeech Clean,Not stated,"Small … LibriSpeech Clean WER ~4%"
benchmark,ASR,Whisper Small,WER,~7%,,,LibriSpeech Other,Not stated,"Small … LibriSpeech Other WER ~7%"
benchmark,ASR,Whisper Medium,WER,~3%,,,LibriSpeech Clean,Not stated,"Medium … LibriSpeech Clean WER ~3%"
benchmark,ASR,Whisper Medium,WER,~6%,,,LibriSpeech Other,Not stated,"Medium … LibriSpeech Other WER ~6%"
benchmark,ASR,Whisper Large / Large-v3,WER,2.7%,2.7,percent,LibriSpeech Clean,Not stated,"Whisper large-v3 achieves 2.7% WER on clean test"
benchmark,ASR,Whisper Large / Large-v3,WER,5.2%,5.2,percent,LibriSpeech Other,Not stated,"5.2% on the more challenging ‘other’ subset"
benchmark,ASR,Whisper (multilingual),WER,~9.0%,,,Common Voice (avg across languages),Not stated,"approximately 9.0% WER averaged across languages"
benchmark,ASR,wav2vec 2.0 Base,WER,4.8%,4.8,percent,LibriSpeech Clean,GPU (unspecified),"base model achieves 4.8% WER on LibriSpeech clean test"
benchmark,ASR,wav2vec 2.0 Large,WER,1.8%,1.8,percent,LibriSpeech (full fine-tuning),GPU (unspecified),"large variant reaching 1.8% WER"
benchmark,ASR,wav2vec 2.0,WER,37.04%,37.04,percent,Ionio Clean Speech,Not stated,"Ionio evaluation … 37.04% WER on clean speech"
benchmark,ASR,wav2vec 2.0,WER,54.69%,54.69,percent,Ionio Noisy Speech,Not stated,"54.69% WER on noisy speech"
benchmark,ASR,Whisper,WER,19.96%,19.96,percent,Ionio Clean Speech,Not stated,"Whisper … 19.96%"
benchmark,ASR,Whisper,WER,29.80%,29.8,percent,Ionio Noisy Speech,Not stated,"Whisper … 29.80%"
benchmark,TTS,Fish Speech V1.5,WER,3.5%,3.5,percent,English,Not stated,"WER 3.5% (English)"
benchmark,TTS,Fish Speech V1.5,CER,1.2%,1.2,percent,English,Not stated,"CER 1.2% (English)"
benchmark,TTS,Fish Speech V1.5,CER,1.3%,1.3,percent,Chinese,Not stated,"1.3% (Chinese)"
benchmark,ASR,Whisper Small,RTF,~0.6,,,Inference,Consumer GPU,"RTF varies … ~0.6 for small variants"
benchmark,ASR,Whisper Large-v3,RTF,~1.0,,,Inference,Consumer GPU,"1.0 for large-v3 on consumer GPU hardware"
benchmark,ASR,Faster Whisper,Speedup,4×,4,x,Optimized inference,CTranslate2,"Faster Whisper achieves up to 4× speedup"
benchmark,ASR,Insanely Fast Whisper,Speedup,9×,9,x,Optimized inference,Not stated,"reports 9× acceleration"
benchmark,ASR,Whisper Turbo,RTF,216× realtime,216,x,Inference,Groq infrastructure,"achieves 216× real-time factor on … Groq"
benchmark,ASR,wav2vec 2.0 Base,RTF,~0.3,,,Inference,Standard GPU,"RTF of ~0.3 for the base model"
benchmark,ASR,Gemini Audio,Latency,<300 ms,,ms,End-to-end,Google TPU,"Latency optimization achieves sub-300ms"
benchmark,TTS,Chatterbox-Turbo,Latency,<200 ms,,ms,TTS,GPU,"sub-200ms inference"
resource,ASR,Whisper Large-v3,VRAM,~16 GB,,GB,Inference,,"requires 16 GB VRAM for large-v3 inference"
resource,ASR,Whisper Medium,VRAM,~5 GB,,GB,Inference,,"medium (~5 GB)"
resource,ASR,Whisper Small,VRAM,~2 GB,,GB,Inference,,"small (~2 GB)"
resource,ASR,Whisper Base,VRAM,~1 GB,,GB,Inference,,"base (~1 GB)"
resource,ASR,Whisper Tiny,VRAM,<500 MB,,MB,Inference,,"tiny (<500 MB)"
resource,AudioGen,MusicGen Medium/Large,VRAM,≥16 GB,,GB,Inference,,"Minimum: 16 GB VRAM"
resource,AudioGen,Stable Audio 2.5,Latency,<2 s / 3 min audio,,s_per_3min_audio,Generation,,"<2 seconds for 3-minute tracks"
resource,AudioGen,ACE-Step 1.5,VRAM,~4 GB,,GB,Inference,,"VRAM requirement: 4 GB"
resource,AudioGen,ACE-Step 1.5,Latency,~2 s (A100),,s,Inference,A100,"~2 seconds on A100"
resource,AudioGen,ACE-Step 1.5,Latency,<10 s,,s,Inference,RTX 3090,"<10 seconds on RTX 3090"
dataset_ref,ASR,LibriSpeech,,,"",,LibriSpeech (Clean / Other),,"Primary ASR benchmark"
dataset_ref,ASR,Common Voice,,,"",,Common Voice,,"Multilingual benchmark"
dataset_ref,ASR,Ionio,,,"",,Ionio,,"Production-style robustness benchmark"
dataset_ref,AudioGen,AudioSet,,,"",,AudioSet,,"AudioGen training data"
dataset_ref,ASR,LibriVox,,,"",,LibriVox,,"wav2vec 2.0 pretraining"

