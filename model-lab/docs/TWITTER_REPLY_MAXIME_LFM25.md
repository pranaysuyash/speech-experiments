# Twitter Reply to Maxime Labonne - LFM2.5 Testing Update

**Thread Reply to**: @maximelabonne's LFM2.5 launch tweet  
**Date**: January 8, 2026

---

## ğŸ¯ Tweet Draft

### Tweet 1 (Main Reply):

```
@maximelabonne Congrats on the LFM2.5 launch! ğŸ‰

Been testing it extensively today on Apple Silicon. Found & fixed two critical bugs preventing MPS support:

1. Processor defaulted to CUDA (now fixed)
2. Audio format mismatch (tensor shape issue)

Now working great on M-series chips! ğŸš€
```

### Tweet 2 (Technical Details):

```
Technical findings:

âœ… LFM2.5-Audio now runs on MPS after fixes
âš¡ RTF: 0.098-0.212x on Apple Silicon
ğŸ“Š Tested on 163s & 944s audio files

Compared vs Whisper/Faster-Whisper baselines. LFM2.5 shines for multi-modal tasks but Whisper variants still better for pure ASR.
```

### Tweet 3 (Community Value):

```
Key issues we solved:

1ï¸âƒ£ LFM2AudioProcessor.from_pretrained() had hardcoded device="cuda"
   â†’ Fixed by loading on CPU first, then .to(device)

2ï¸âƒ£ ChatState.add_audio() expects (channels, samples) tensors
   â†’ Fixed with proper numpyâ†’tensor conversion

Hope this helps others on Apple Silicon! ğŸ
```

### Tweet 4 (Results Link):

```
Full technical writeup & benchmarks:
- Detailed bug analysis
- MPS performance metrics
- Comparative results vs Whisper

Available in our model-lab repo. LFM2.5 is an exciting multi-modal model - looking forward to seeing it evolve! ğŸš€
```

---

## ğŸ“± Alternative: Single Concise Tweet

```
@maximelabonne Tested LFM2.5-Audio extensively on Apple Silicon today!

Fixed 2 bugs blocking MPS:
â€¢ Processor CUDA default â†’ load on CPU first
â€¢ Audio tensor shape mismatch â†’ proper conversion

Now getting 0.10x RTF on M-series ğŸš€

Compared vs Whisper - LFM2.5 great for multi-modal, Whisper still king for pure ASR

Full writeup with benchmarks in our repo!
```

---

## ğŸ¯ Key Messages to Convey

1. **Appreciation**: Acknowledge Maxime's work on LFM2.5
2. **Community Contribution**: Share bug fixes to help others
3. **Technical Credibility**: Show real testing/benchmarking
4. **Balanced Assessment**: Honest comparison without negativity
5. **Open Collaboration**: Offer findings to improve the ecosystem

---

## ğŸ“Š Supporting Data Points

### Performance on Apple Silicon:

- **LFM2.5**: RTF 0.098-0.212x (sub-realtime âœ…)
- **Device**: MPS (Apple Silicon acceleration)
- **Test Files**: 163s and 944s audio

### Bugs Fixed:

1. Processor loading (CUDA hardcode)
2. Audio format (numpyâ†’tensor conversion)

### Comparative Results:

- **ASR Accuracy**: Whisper/Faster-Whisper superior
- **Multi-modal**: LFM2.5 unique capability
- **Production Use**: Whisper variants for ASR, LFM2.5 for conversational AI

---

## âœ… What We Validated

- âœ… LFM2.5 works on Apple Silicon (MPS)
- âœ… Sub-realtime inference achieved
- âœ… Proper device handling fixed
- âœ… Audio format compatibility resolved
- âœ… Comprehensive benchmarking complete

---

## ğŸš€ Impact

**For the Community**:

- Apple Silicon users can now use LFM2.5
- Clear bug fixes documented
- Performance expectations set

**For LiquidAI**:

- Bug reports with solutions
- Real-world usage data
- Constructive feedback

**For Our Project**:

- Production-ready ASR pipeline
- Multi-model comparison baseline
- Apple Silicon optimization validated

---

## ğŸ“ References to Include

- GitHub repo: model-lab
- Technical doc: LFM_MPS_FIX_SUMMARY.md
- Test results: COMPREHENSIVE_TEST_RESULTS_2026-01-08.md
- Comparative analysis: Available in runs/ directory

---

## ğŸ¨ Tone & Style

- âœ… Enthusiastic but professional
- âœ… Technical but accessible
- âœ… Appreciative and constructive
- âœ… Data-driven and factual
- âŒ Avoid: Overly critical, dismissive, or promotional

---

**Recommendation**: Use the threaded approach (Tweets 1-4) for maximum detail, or the single concise tweet for simplicity. Both convey the key findings while maintaining positive community engagement.
