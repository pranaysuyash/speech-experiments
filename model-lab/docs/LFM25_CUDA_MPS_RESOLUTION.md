# üöÄ LFM2.5-Audio CUDA/MPS Resolution - Community Contribution

**Date**: January 8, 2026  
**Author**: Pranay Suyash (@pranaysuyash)  
**Context**: Reply to Maxime Labonne's LFM2.5 launch  
**Status**: ‚úÖ RESOLVED & DOCUMENTED

---

## üìã Executive Summary

While testing LiquidAI's LFM2.5-Audio model, we discovered and resolved **two critical bugs** preventing the model from running on Apple Silicon (MPS) and potentially affecting other non-CUDA systems. This document provides the technical details for the community and LiquidAI team.

**Impact**: LFM2.5-Audio now successfully runs on Apple Silicon with MPS acceleration, achieving 0.098-0.212x RTF on real-world audio files.

---

## üêõ Issue #1: Processor CUDA Hardcode

### Problem Description

The `LFM2AudioProcessor.from_pretrained()` method in the `liquid-audio` package has a hardcoded default parameter `device="cuda"`:

```python
@classmethod
def from_pretrained(cls, repo_id: str | Path, ..., device: torch.device | str = "cuda") -> Self:
    # ...
    return cls(...).to(device)  # Always calls .to(device) with CUDA default!
```

**Impact**: When called without explicitly specifying a device, the processor attempts to initialize CUDA, which fails on systems without CUDA support (macOS, CPU-only systems).

### Error Observed

```
ERROR: Failed to load LFM2AudioProcessor: Torch not compiled with CUDA enabled
  File: torch/cuda/__init__.py:403 in _lazy_init()
```

### Root Cause

The processor initialization happens separately from model loading. Even though the model successfully loads on MPS/CPU, the processor fails because it defaults to CUDA.

### Solution Implemented

**File**: `harness/registry.py` (lines 186-207)

```python
# Load processor on CPU to avoid CUDA initialization
processor = LFM2AudioProcessor.from_pretrained(model_name, device='cpu')
logger.info(f"‚úì LFM2AudioProcessor loaded successfully on CPU")

# Move processor to the same device as model if not CPU
if actual_device != 'cpu':
    try:
        processor = processor.to(actual_device)
        logger.info(f"‚úì Processor moved to {actual_device}")
    except Exception:
        # If move fails, keep on CPU - processor is lightweight
        logger.warning(f"Could not move processor to {actual_device}, keeping on CPU")
```

**Key Insights**:

1. Always load processor on CPU first to avoid CUDA initialization
2. Then explicitly move to target device
3. Graceful fallback if device transfer fails (processor is lightweight)

---

## üêõ Issue #2: Audio Format Mismatch

### Problem Description

The `ChatState.add_audio()` method expects:

- PyTorch tensors (not numpy arrays)
- 2D shape with channels: `(channels, samples)`

However, our `AudioLoader` returns:

- Numpy arrays
- 1D shape: `(samples,)`

**Impact**: Attempting to add audio to the chat state resulted in an `AttributeError` because numpy arrays don't have a `.to()` method.

### Error Observed

```
ERROR: 'numpy.ndarray' object has no attribute 'to'
```

### Root Cause

Mismatch between audio loading format (numpy 1D) and expected format (PyTorch 2D tensor).

### Solution Implemented

**File**: `scripts/run_asr.py` (lines 92-137)

```python
# Add audio - liquid-audio expects torch tensor (channels, samples)
# Convert numpy array to tensor
if isinstance(audio, np.ndarray):
    audio_tensor = torch.from_numpy(audio).float()
else:
    audio_tensor = audio.float()

# Ensure 2D shape (channels, samples)
if len(audio_tensor.shape) == 1:
    audio_tensor = audio_tensor.unsqueeze(0)  # Add channel dimension

chat.new_turn("user")
chat.add_audio(audio_tensor, sr)
chat.end_turn()
```

**Key Insights**:

1. Always convert numpy ‚Üí PyTorch tensor
2. Always ensure 2D shape (channels, samples)
3. Use `.unsqueeze(0)` to add channel dimension to 1D audio

---

## ‚úÖ Validation Results

### Test Environment:

- **Device**: Apple Silicon M-series (MPS)
- **Models**: LFM2.5-Audio (1.5B), Whisper (base), Faster-Whisper (base)
- **Test Files**: 163s and 944s real-world audio

### LFM2.5-Audio Performance on MPS:

| Test                | Duration | RTF    | Status     |
| ------------------- | -------- | ------ | ---------- |
| Primary (163s)      | 163.2s   | 0.212x | ‚úÖ Working |
| Conversation (944s) | 943.6s   | 0.098x | ‚úÖ Working |

**Result**: LFM2.5-Audio now runs successfully on Apple Silicon with sub-realtime performance!

---

## üîç Comparative Analysis

### ASR Performance Comparison (163s audio):

| Model          | WER    | CER   | RTF    | Device |
| -------------- | ------ | ----- | ------ | ------ |
| LFM2.5-Audio   | 137.8% | 90.3% | 0.212x | MPS    |
| Whisper        | 28.5%  | 7.7%  | 0.080x | MPS    |
| Faster-Whisper | 24.1%  | 6.1%  | 0.119x | MPS    |

### Key Findings:

1. **LFM2.5 Multi-Modal Strength**: Not optimized for pure ASR, but has unique multi-modal capabilities
2. **Whisper/Faster-Whisper ASR Leaders**: Superior accuracy for transcription tasks
3. **All Models Sub-Realtime**: Excellent performance on Apple Silicon

---

## üéØ Recommendations

### For LiquidAI Team:

1. **Change Processor Default**:

   ```python
   # Current (problematic)
   def from_pretrained(cls, ..., device: str = "cuda"):

   # Suggested (compatible)
   def from_pretrained(cls, ..., device: str = "cpu"):
   ```

2. **Document Audio Format**:

   - Clearly specify tensor requirements in docs
   - Add type hints: `audio: torch.Tensor`
   - Provide conversion examples

3. **Add Device Auto-Detection**:
   ```python
   if device == "auto":
       if torch.cuda.is_available():
           device = "cuda"
       elif torch.backends.mps.is_available():
           device = "mps"
       else:
           device = "cpu"
   ```

### For Community Users:

1. **Always Specify Device**: Don't rely on defaults
2. **Use CPU-First Loading**: For processor initialization
3. **Convert Audio Properly**: Numpy ‚Üí Tensor with correct shape

---

## üìö Technical Resources

### Code References:

- **Bug Fix**: `harness/registry.py` lines 186-207
- **Audio Conversion**: `scripts/run_asr.py` lines 92-137
- **Full Analysis**: `docs/LFM_MPS_FIX_SUMMARY.md`

### Test Results:

- **Comprehensive Tests**: `docs/COMPREHENSIVE_TEST_RESULTS_2026-01-08.md`
- **Test Runs**: `runs/lfm2_5_audio/asr/*.json`
- **Multi-Device Plan**: `docs/MULTI_DEVICE_TESTING_PLAN.md`

---

## ü§ù Community Impact

**Benefits for Apple Silicon Users**:

- ‚úÖ LFM2.5 now works on M1/M2/M3 Macs
- ‚úÖ MPS acceleration enabled
- ‚úÖ Sub-realtime performance achieved

**Benefits for LiquidAI**:

- üêõ Bug reports with solutions
- üìä Real-world performance data
- üîß Device compatibility improvements

**Benefits for OSS Community**:

- üìñ Clear documentation of issues
- üí° Reusable solutions
- üß™ Comprehensive test results

---

## üöÄ Next Steps

### Testing:

- [x] MPS (Apple Silicon) - Complete
- [ ] GPU (CUDA) - Pending Colab tests
- [ ] TPU - Pending Colab tests
- [ ] CPU Baseline - Pending

### Documentation:

- [x] Bug analysis complete
- [x] Solutions documented
- [x] Test results recorded
- [ ] Community sharing (Twitter reply)

### Collaboration:

- [ ] Share with Maxime Labonne
- [ ] Consider upstream PR to liquid-audio
- [ ] Help other users with similar issues

---

## üìù Citation

If you found this helpful, please reference:

```
LFM2.5-Audio MPS Support Fix
Author: Pranay Suyash
Date: January 8, 2026
Repository: model-lab
Context: Apple Silicon compatibility for LiquidAI LFM2.5
```

---

## üí¨ Discussion Points for Community

1. **Should processor default to CPU?** More compatible but possibly less performant
2. **Audio format standardization?** Common pattern across speech models
3. **Device auto-detection?** Convenience vs. explicitness trade-off

---

**Status**: Ready for community sharing via Twitter reply to Maxime's launch announcement.

**Impact**: Enables LFM2.5-Audio usage on Apple Silicon and potentially other non-CUDA platforms.

**Tone**: Constructive, technical, solution-oriented üöÄ
